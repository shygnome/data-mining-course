{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cOgF3m-Oo2kE"
   },
   "source": [
    "<h2><center>Tugas 3 Data Mining 2019/2020</center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DgqyG8Zyo2kK"
   },
   "source": [
    "<center><font color=\"red\">Deadline: 17 October 2019, 22:00WIB</font><center>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1UCOtummo2kQ"
   },
   "source": [
    "<h4>Nama    : Muhammad Yudistira Hanifmuti </h4>\n",
    "<h4>NPM     : 1606829560 </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gq1mXznao2kV"
   },
   "source": [
    "<b>Petunjuk umum:</b>\n",
    "1. Dataset yang digunakan pada tugas ini merupakan dataset diabetes yang dapat diunduh di https://bit.ly/2M5vioB\n",
    "2. Deskripsi atribut pada dataset dapat dilihat pada halaman tersebut.\n",
    "3. Lakukan pengolahan data dan perhitungan menggunakan bahasa pemrograman 4. Python. Gunakan template Jupyter notebook yang telah disediakan untuk menjawab soal.\n",
    "4. Penggunaan Library dibatasi hanya untuk penggunaan numpy array. \n",
    "5. Format penulisan nama file di Jupyter notebook: T3_Nama_NIM.ipynb\n",
    "Kumpulkan pada slot yang disediakan di scele. Deadline:.\n",
    "6. Jika dalam menyelesaikan tugas ini anda berkolaborasi dengan orang lain, silahkan dituliskan dengan siapa anda berkolaborasi (pada baris ini)!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vuphuxNFo2kY"
   },
   "source": [
    "<b>K-Nearest Neighbor (KNN) (total - poin)</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MphVuV2mpPWR"
   },
   "source": [
    "1. <b>[- poin]</b> Lakukan range normalization pada dataset diabetes.\n",
    " \n",
    "2. <b>[- poin]</b> Hitung distance matrix dari dataset dengan menggunakan :\n",
    "\n",
    "    a. Manhattan distance\n",
    "    \n",
    "    b. Euclidean distance\n",
    "    \n",
    "    c. Cosine distance\n",
    "    \n",
    "2. <b>[- poin]</b> Pilihlah 10 data secara acak dari dataset, lakukan proses K-NN untuk menentukan kelas dari data tersebut dengan nilai K = 3, 5, dan 7. Untuk setiap nilai K, bandingkan hasil klasifikasi dengan menggunakan ukuran jarak Manhattan distance, Euclidean distance, dan Cosine distance. Apakah ada perbedaan ? Lakukan analisis singkat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tlwpfbcbo2kl"
   },
   "source": [
    "Jawaban :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5U1w5jRRo2kp"
   },
   "source": [
    "1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MphVtoRco2kt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset yang sudah dikenakan range normalization memiliki hasil akhir sebagai berikut.\n",
      "a. Nilai minimum sama dengan 0\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "b. Nilai maksimum sama dengan 1\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "\n",
    "# Dataset metadata\n",
    "dataset_url = \"https://drive.google.com/uc?authuser=0&id=1uxN2XunIHEhtv03dHgM9gE_J8i4QvKzU&export=download\"\n",
    "filename = 'diabetes.csv'\n",
    "columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\n",
    "\n",
    "# Function\n",
    "\n",
    "def load_dataset():\n",
    "    ## Download and write diabetes data\n",
    "    if not (os.path.exists(filename)):\n",
    "        r = requests.get(dataset_url, allow_redirects=True)\n",
    "        open(filename, 'wb').write(r.content)\n",
    "    \n",
    "    ## Read diabetes data\n",
    "    dataset = np.genfromtxt(filename, delimiter=',', skip_header=1)\n",
    "    return dataset\n",
    "\n",
    "def min_over_cols(data):\n",
    "    return [data[:,i].min() for i in range(data.shape[1])]\n",
    "\n",
    "def max_over_cols(data):\n",
    "    return [data[:,i].max() for i in range(data.shape[1])]\n",
    "\n",
    "def range_normalization(data):\n",
    "    ## Compute range\n",
    "    min_vals = min_over_cols(data)\n",
    "    max_vals = max_over_cols(data)\n",
    "    range_r = [max_vals[i]-min_vals[i] for i in range(data.shape[1])]\n",
    "    \n",
    "    ## Compute normalization\n",
    "    return (data - min_vals)/range_r\n",
    "    \n",
    "# Load dataset, then normalize\n",
    "dataset = load_dataset()\n",
    "normalized = range_normalization(dataset)\n",
    "\n",
    "print(\"Dataset yang sudah dikenakan range normalization memiliki hasil akhir sebagai berikut.\")\n",
    "print(\"a. Nilai minimum sama dengan 0\")\n",
    "print(min_over_cols(normalized))\n",
    "print(\"b. Nilai maksimum sama dengan 1\")\n",
    "print(max_over_cols(normalized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8ZktDNKGo2k6"
   },
   "source": [
    "2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TUyX_42_o2k_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berikut ini adalah hasil perhitungan distance matrix menggunakan beberapa jenis distance.\n",
      "\n",
      "a. Manhattan Distance\n",
      "[[0.         1.25932352 1.18535216 ... 1.0548267  1.07742934 1.25820653]\n",
      " [1.25932352 0.         1.41645909 ... 0.72626112 0.86782136 0.29852661]\n",
      " [1.18535216 1.41645909 0.         ... 1.1771883  1.22024134 1.63458369]\n",
      " ...\n",
      " [1.0548267  0.72626112 1.1771883  ... 0.         1.10935337 0.81473566]\n",
      " [1.07742934 0.86782136 1.22024134 ... 1.10935337 0.         0.97991612]\n",
      " [1.25820653 0.29852661 1.63458369 ... 0.81473566 0.97991612 0.        ]]\n",
      "\n",
      "b. Euclidean Distance\n",
      "[[0.         0.56380025 0.53665043 ... 0.45162548 0.50269284 0.62234648]\n",
      " [0.56380025 0.         0.7208524  ... 0.33774235 0.45222484 0.15595016]\n",
      " [0.53665043 0.7208524  0.         ... 0.4901339  0.58690672 0.72903545]\n",
      " ...\n",
      " [0.45162548 0.33774235 0.4901339  ... 0.         0.47201476 0.34337787]\n",
      " [0.50269284 0.45222484 0.58690672 ... 0.47201476 0.         0.5408326 ]\n",
      " [0.62234648 0.15595016 0.72903545 ... 0.34337787 0.5408326  0.        ]]\n",
      "\n",
      "c. Cosine Similarity/Distance\n",
      "[[1.11022302e-16 5.98055416e-02 8.78601936e-02 ... 4.85506377e-02\n",
      "  6.62789090e-02 1.03610090e-01]\n",
      " [5.98055416e-02 0.00000000e+00 1.73354587e-01 ... 5.02957766e-02\n",
      "  1.01647386e-01 1.29630935e-02]\n",
      " [8.78601936e-02 1.73354587e-01 0.00000000e+00 ... 7.44186637e-02\n",
      "  1.14784124e-01 1.84873520e-01]\n",
      " ...\n",
      " [4.85506377e-02 5.02957766e-02 7.44186637e-02 ... 2.22044605e-16\n",
      "  1.05852662e-01 5.67162872e-02]\n",
      " [6.62789090e-02 1.01647386e-01 1.14784124e-01 ... 1.05852662e-01\n",
      "  0.00000000e+00 1.48899510e-01]\n",
      " [1.03610090e-01 1.29630935e-02 1.84873520e-01 ... 5.67162872e-02\n",
      "  1.48899510e-01 2.22044605e-16]]\n"
     ]
    }
   ],
   "source": [
    "# Separate target from data\n",
    "X, y = normalized[:, :-1], normalized[:, -1]\n",
    "\n",
    "# Function\n",
    "def manhattan_distance(v, w):\n",
    "    return np.sum(np.absolute(v-w))\n",
    "\n",
    "def euclidean_distance(v, w):\n",
    "    return np.sqrt(np.sum(np.power(v-w, 2)))\n",
    "\n",
    "def cosine_distance(v, w):\n",
    "    ## norm 2 function\n",
    "    def norm(v):\n",
    "        return np.sqrt(np.sum(np.power(v, 2)))\n",
    "    return 1 - (np.dot(v, w)/(norm(v)*norm(w)))\n",
    "\n",
    "def distance_matrix(data, distance_type='euclidean'):\n",
    "    ## Check used distance type\n",
    "    if distance_type == 'euclidean':\n",
    "        distance_fun = euclidean_distance\n",
    "    elif distance_type == 'manhattan':\n",
    "        distance_fun = manhattan_distance\n",
    "    elif distance_type == 'cosine':\n",
    "        distance_fun = cosine_distance\n",
    "    else:\n",
    "        raise ValueError('Distance type is not recognized.')\n",
    "    \n",
    "    ## Compute distance\n",
    "    data_length = data.shape[0]\n",
    "    mat = np.array([np.array([distance_fun(data[i], data[j]) for j in range(data_length)]) for i in range(data_length)])\n",
    "    return mat\n",
    "\n",
    "distance_1 = distance_matrix(X, distance_type='manhattan')\n",
    "distance_2 = distance_matrix(X, distance_type='euclidean')\n",
    "distance_3 = distance_matrix(X, distance_type='cosine')\n",
    "\n",
    "print(\"Berikut ini adalah hasil perhitungan distance matrix menggunakan beberapa jenis distance.\")\n",
    "print()\n",
    "print(\"a. Manhattan Distance\")\n",
    "print(distance_1)\n",
    "print()\n",
    "print(\"b. Euclidean Distance\")\n",
    "print(distance_2)\n",
    "print()\n",
    "print(\"c. Cosine Similarity/Distance\")\n",
    "print(distance_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Gsmcskmo2lK"
   },
   "source": [
    "3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OXddiJa4o2lP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data yang terpilih adalah data dengan index [102 435 270 106  71 700  20 614 121 466]\n",
      "Target yang benar dari data terpilih adalah [0. 1. 1. 0. 0. 0. 0. 1. 0. 0.]\n",
      "Di bawah ini adalah hasil klasifikasi untuk setiap konfigurasi.\n",
      "\n",
      "1 k = 3\n",
      " a) Manhattan distance\n",
      "    Hasil klasifikasi adalah [0 1 1 0 1 0 0 1 0 0]\n",
      "    Prediksi yang salah sejumlah 1 data\n",
      "\n",
      " b) Euclidean distance\n",
      "    Hasil klasifikasi adalah [0 1 1 0 0 0 1 1 0 0]\n",
      "    Prediksi yang salah sejumlah 1 data\n",
      "\n",
      " c) Cosine distance\n",
      "    Hasil klasifikasi adalah [0 1 1 0 1 0 0 1 0 0]\n",
      "    Prediksi yang salah sejumlah 1 data\n",
      "\n",
      "2 k = 5\n",
      " a) Manhattan distance\n",
      "    Hasil klasifikasi adalah [0 1 1 0 1 0 1 1 0 0]\n",
      "    Prediksi yang salah sejumlah 2 data\n",
      "\n",
      " b) Euclidean distance\n",
      "    Hasil klasifikasi adalah [0 1 1 0 0 0 1 1 0 0]\n",
      "    Prediksi yang salah sejumlah 1 data\n",
      "\n",
      " c) Cosine distance\n",
      "    Hasil klasifikasi adalah [0 1 1 0 1 0 0 1 0 0]\n",
      "    Prediksi yang salah sejumlah 1 data\n",
      "\n",
      "3 k = 7\n",
      " a) Manhattan distance\n",
      "    Hasil klasifikasi adalah [0 1 1 0 1 0 0 1 0 0]\n",
      "    Prediksi yang salah sejumlah 1 data\n",
      "\n",
      " b) Euclidean distance\n",
      "    Hasil klasifikasi adalah [0 1 1 0 0 0 0 1 0 0]\n",
      "    Prediksi yang salah sejumlah 0 data\n",
      "\n",
      " c) Cosine distance\n",
      "    Hasil klasifikasi adalah [0 1 1 0 0 0 0 1 0 0]\n",
      "    Prediksi yang salah sejumlah 0 data\n",
      "\n",
      "\n",
      "\n",
      "Dapat dilihat bahwa KNN sudah cukup berhasil melakukan klasifikasi dengan rata-rata kesalahan prediksi hanya 1 data.\n",
      "Untuk setiap nilai k, manhattan distance memiliki kesalahan yang lebih banyak bila dibandingkan dengan distance\n",
      "yang lain sehingga dapat dikatakan bahwa untuk data diabetes ini manhattan distance kurang tepat untuk digunakan.\n",
      "Untuk pemilihan nilai k, dapat dilihat bahwa secara umum k = 7 memiliki kesalahan prediksi lebih sedikit.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification routine\n",
    "def routine(X, y):\n",
    "    ## Random sampling 10 data\n",
    "    np.random.seed(42)\n",
    "    idx = np.random.choice(X.shape[0], 10)\n",
    "    X_test = X[idx]\n",
    "    y_test = y[idx]\n",
    "    \n",
    "    ## knn process\n",
    "    def do_knn(distance_matrix, k=3):\n",
    "        k_nearest_idx = np.argsort(distance_matrix[idx])[:,:k]\n",
    "        k_nearest_target = np.array(list(map(lambda x: y[x], k_nearest_idx)))\n",
    "        test_target = np.array(list(map(lambda x: np.bincount(x.astype(int)).argmax(), k_nearest_target)))\n",
    "        return test_target\n",
    "    \n",
    "    ## count wrong prediction\n",
    "    def wrong_pred(pred, test):\n",
    "        diff = abs(pred - test)\n",
    "        return np.sum(np.array(list(map(lambda x: 1 if x > 0 else 0, diff))))\n",
    "    \n",
    "    ## Calculate distance matrix\n",
    "    distance_1 = distance_matrix(X, distance_type='manhattan')\n",
    "    distance_2 = distance_matrix(X, distance_type='euclidean')\n",
    "    distance_3 = distance_matrix(X, distance_type='cosine')\n",
    "    \n",
    "    print(\"Data yang terpilih adalah data dengan index\", idx)\n",
    "    print(\"Target yang benar dari data terpilih adalah\", y_test)\n",
    "    print(\"Di bawah ini adalah hasil klasifikasi untuk setiap konfigurasi.\")\n",
    "    print()\n",
    "    \n",
    "    ## Do knn\n",
    "    k_vals = [3, 5, 7]\n",
    "    for i,k in enumerate(k_vals):\n",
    "        print(i+1, \"k =\", k)\n",
    "        \n",
    "        print(\" a) Manhattan distance\")\n",
    "        result = do_knn(distance_1, k=k)\n",
    "        print(\"    Hasil klasifikasi adalah\", result)\n",
    "        print(\"    Prediksi yang salah sejumlah\", wrong_pred(result, y_test), \"data\")\n",
    "        print()\n",
    "        print(\" b) Euclidean distance\")\n",
    "        result = do_knn(distance_2, k=k)\n",
    "        print(\"    Hasil klasifikasi adalah\", result)\n",
    "        print(\"    Prediksi yang salah sejumlah\", wrong_pred(result, y_test), \"data\")\n",
    "        print()\n",
    "        print(\" c) Cosine distance\")\n",
    "        result = do_knn(distance_3, k=k)\n",
    "        print(\"    Hasil klasifikasi adalah\", result)\n",
    "        print(\"    Prediksi yang salah sejumlah\", wrong_pred(result, y_test), \"data\")\n",
    "        print()\n",
    "\n",
    "\n",
    "routine(X, y)\n",
    "\n",
    "analisis = \"\"\"\n",
    "Dapat dilihat bahwa KNN sudah cukup berhasil melakukan klasifikasi dengan rata-rata kesalahan prediksi hanya 1 data.\n",
    "Untuk setiap nilai k, manhattan distance memiliki kesalahan yang lebih banyak bila dibandingkan dengan distance\n",
    "yang lain sehingga dapat dikatakan bahwa untuk data diabetes ini manhattan distance kurang tepat untuk digunakan.\n",
    "Untuk pemilihan nilai k, dapat dilihat bahwa secara umum k = 7 memiliki kesalahan prediksi lebih sedikit.\n",
    "\"\"\"\n",
    "print()\n",
    "print(analisis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gsv9hUr-o2lx"
   },
   "source": [
    "<b>Naive Bayes (total - poin)</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hqtJ7EeVo2l0"
   },
   "source": [
    "1. <b>[- poin]</b>  Lakukan klasifikasi pada dataset diabetes yang telah dinormalisasi menggunakan algoritma Naive Bayes. Proporsi pembagian data training dan testing adalah 80:20.\n",
    "2. <b>[- poin]</b> Hitung hasil akurasi.\n",
    "$$accuracy = \\frac{number \\:of \\:true \\:predictions}{number \\:of \\:total \\:predictions}$$ \n",
    "3. <b>[- poin]</b> Carilah correlation coefficient untuk setiap pasang fitur pada dataset diabetes yang telah dinormalisasi.\n",
    "4. <b>[- poin]</b> Hapus fitur-fitur yang saling berkorelasi, lalu lakukan kembali klasifikasi menggunakan algoritma Naive Bayes menggunakan fitur yang tersisa. Bandingkan hasil klasifikasi untuk data train dan data test (menggunakan hasil soal no.2) dari dua skenario tersebut dan berikan analisis mengenai hasil yang diperoleh."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FJBeFMtqo2l4"
   },
   "source": [
    "1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tM4ejKm_o2l8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil prediksi Naive Bayes untuk 20% data test adalah sebagai berikut.\n",
      "[1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1.\n",
      " 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0.\n",
      " 0. 1. 0. 1. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Classifier\n",
    "class GaussianNB:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # Get data information\n",
    "        self.classes = np.unique(y)\n",
    "        self.n_classes = self.classes.shape[0]\n",
    "        self.n_features = X.shape[1]\n",
    "        \n",
    "        # Initialize nb parameter\n",
    "        self.prior = np.zeros(self.n_classes)\n",
    "        self.mean = np.zeros((self.n_classes, self.n_features))\n",
    "        self.variance = np.zeros((self.n_classes, self.n_features))\n",
    "        \n",
    "        # Compute parameter\n",
    "        for i in range(self.n_classes):\n",
    "            ## Get class data\n",
    "            cls = self.classes[i]\n",
    "            idx = y == cls\n",
    "            D_i = X[idx]\n",
    "            n_rows = D_i.shape[0]\n",
    "            \n",
    "            ## Compute class-specific parameter\n",
    "            \n",
    "            self.prior[i] = n_rows/X.shape[0]\n",
    "            self.mean[i] = np.sum(D_i, axis=0)/n_rows\n",
    "            \n",
    "            ### Compute attribute variance\n",
    "            centered_D = D_i - self.mean[i]\n",
    "            for j in range(self.n_features):\n",
    "                v = centered_D[:, j]\n",
    "                self.variance[i, j] = np.dot(v, v)/n_rows\n",
    "        return X\n",
    "    \n",
    "    def _predict_row(self, x):\n",
    "        # Likelihood function\n",
    "        def likelihood(x, mean, variance):\n",
    "            exponent = np.exp(-(np.power(x-mean, 2)/(2*variance)))\n",
    "            return (exponent/(np.sqrt(2*np.pi)*np.sqrt(self.variance[i, j])))\n",
    "            \n",
    "        # Initialize probability for each class\n",
    "        prob = np.zeros(self.n_classes)\n",
    "        \n",
    "        # Compute likelihood\n",
    "        for i in range(self.n_classes):\n",
    "            prior = self.prior[i]\n",
    "            \n",
    "            likelihood = 1\n",
    "            for j in range(self.n_features):\n",
    "                exponent = np.exp(-(np.power(x[j]-self.mean[i, j], 2)/(2*self.variance[i, j])))\n",
    "                likelihood *= (exponent/(np.sqrt(2*np.pi)*np.sqrt(self.variance[i, j])))\n",
    "            prob[i] = prior * likelihood\n",
    "        \n",
    "        # Return argmax\n",
    "        return self.classes[np.argmax(prob)]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict_row(x) for x in X])\n",
    "\n",
    "# Split datasetfan\n",
    "split_point = int(X.shape[0]*0.8)\n",
    "X, y = normalized[:, :-1], normalized[:, -1]\n",
    "X_train, X_test = X[:split_point], X[split_point:]\n",
    "y_train, y_test = y[:split_point], y[split_point:]\n",
    "\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train,y_train)\n",
    "y_pred = nb.predict(X_test)\n",
    "print(\"Hasil prediksi Naive Bayes untuk 20% data test adalah sebagai berikut.\")\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZOTELtSAo2mG"
   },
   "source": [
    "2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "16WW2PKoo2mL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil akurasi dari prediksi Naive Bayes adalah 0.7467532467532467\n"
     ]
    }
   ],
   "source": [
    "# accuracy score\n",
    "def accuracy_score(pred, target):\n",
    "    true_pred = np.sum(pred == target)\n",
    "    return true_pred/pred.shape[0]\n",
    "\n",
    "print(\"Hasil akurasi dari prediksi Naive Bayes adalah\", accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "206IiaWRo2mS"
   },
   "source": [
    "3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iSoivKkMo2mV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation coefficient untuk setiap pasang fitur pada dataset adalah sebagai berikut.\n",
      "Fitur Pregnancies (1) dengan Glucose (2)\n",
      "0.12945867149927248\n",
      "\n",
      "Fitur Pregnancies (1) dengan BloodPressure (3)\n",
      "0.14128197740713994\n",
      "\n",
      "Fitur Pregnancies (1) dengan SkinThickness (4)\n",
      "-0.08167177444900722\n",
      "\n",
      "Fitur Pregnancies (1) dengan Insulin (5)\n",
      "-0.0735346143516281\n",
      "\n",
      "Fitur Pregnancies (1) dengan BMI (6)\n",
      "0.017683090727830593\n",
      "\n",
      "Fitur Pregnancies (1) dengan DiabetesPedigreeFunction (7)\n",
      "-0.03352267296261312\n",
      "\n",
      "Fitur Pregnancies (1) dengan Age (8)\n",
      "0.5443412284023389\n",
      "\n",
      "Fitur Glucose (2) dengan BloodPressure (3)\n",
      "0.15258958656866448\n",
      "\n",
      "Fitur Glucose (2) dengan SkinThickness (4)\n",
      "0.05732789073817704\n",
      "\n",
      "Fitur Glucose (2) dengan Insulin (5)\n",
      "0.3313571099202091\n",
      "\n",
      "Fitur Glucose (2) dengan BMI (6)\n",
      "0.22107106945898297\n",
      "\n",
      "Fitur Glucose (2) dengan DiabetesPedigreeFunction (7)\n",
      "0.1373372998283707\n",
      "\n",
      "Fitur Glucose (2) dengan Age (8)\n",
      "0.2635143198243335\n",
      "\n",
      "Fitur BloodPressure (3) dengan SkinThickness (4)\n",
      "0.2073705384030709\n",
      "\n",
      "Fitur BloodPressure (3) dengan Insulin (5)\n",
      "0.08893337837319303\n",
      "\n",
      "Fitur BloodPressure (3) dengan BMI (6)\n",
      "0.28180528884991063\n",
      "\n",
      "Fitur BloodPressure (3) dengan DiabetesPedigreeFunction (7)\n",
      "0.041264947930098564\n",
      "\n",
      "Fitur BloodPressure (3) dengan Age (8)\n",
      "0.23952794642136352\n",
      "\n",
      "Fitur SkinThickness (4) dengan Insulin (5)\n",
      "0.436782570120013\n",
      "\n",
      "Fitur SkinThickness (4) dengan BMI (6)\n",
      "0.3925732041590383\n",
      "\n",
      "Fitur SkinThickness (4) dengan DiabetesPedigreeFunction (7)\n",
      "0.18392757295416323\n",
      "\n",
      "Fitur SkinThickness (4) dengan Age (8)\n",
      "-0.11397026236774166\n",
      "\n",
      "Fitur Insulin (5) dengan BMI (6)\n",
      "0.19785905649310098\n",
      "\n",
      "Fitur Insulin (5) dengan DiabetesPedigreeFunction (7)\n",
      "0.18507092916809906\n",
      "\n",
      "Fitur Insulin (5) dengan Age (8)\n",
      "-0.042162954735376866\n",
      "\n",
      "Fitur BMI (6) dengan DiabetesPedigreeFunction (7)\n",
      "0.14064695254510515\n",
      "\n",
      "Fitur BMI (6) dengan Age (8)\n",
      "0.03624187009229412\n",
      "\n",
      "Fitur DiabetesPedigreeFunction (7) dengan Age (8)\n",
      "0.033561312434805514\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute corrcoef\n",
    "corrcoef = np.corrcoef(normalized.T)\n",
    "\n",
    "print(\"Correlation coefficient untuk setiap pasang fitur pada dataset adalah sebagai berikut.\")\n",
    "\n",
    "for i in range(corrcoef.shape[0]):\n",
    "    for j in range(i, corrcoef.shape[1]):\n",
    "        if i != j and j != 8:\n",
    "            print(\"Fitur\", columns[i], \"(\"+str(i+1)+\")\", \"dengan\", columns[j], \"(\"+str(j+1)+\")\",)\n",
    "            print(corrcoef[i, j])\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "feePGa-No2mc"
   },
   "source": [
    "4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bthwWjzyo2md"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil akurasi dari prediksi Naive Bayes adalah 0.7532467532467533\n",
      "\n",
      "\n",
      "Hasil akurasi pada skenario kedua setelah dihapus sebagian kolom lebih tinggi ketimbang sebelum dihapus.\n",
      "Dua fitur yang memiliki koefisien korelasi yang tinggi dapat berpotensi menjadi data yang redundan sehingga\n",
      "classifier berpotensi mempelajari data yang salah. Namun, pada kasus ini penghapusan kolom tersebut tidak terlalu\n",
      "signifikan karena nilai koefisien korelasi dari fitur tersebut tidak cukup tinggi untuk dikatakan berkorelasi.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dropped = normalized[:, [0, 1, 2, 3, 4, 5, 6, 8]]\n",
    "new_X, new_y = dropped[:, :-1], dropped[:, -1]\n",
    "X_train, X_test = new_X[:split_point], new_X[split_point:]\n",
    "y_train, y_test = new_y[:split_point], new_y[split_point:]\n",
    "\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train,y_train)\n",
    "y_pred = nb.predict(X_test)\n",
    "print(\"Hasil akurasi dari prediksi Naive Bayes adalah\", accuracy_score(y_pred, y_test))\n",
    "print()\n",
    "\n",
    "analisis = \"\"\"\n",
    "Hasil akurasi pada skenario kedua setelah dihapus sebagian kolom lebih tinggi ketimbang sebelum dihapus.\n",
    "Dua fitur yang memiliki koefisien korelasi yang tinggi dapat berpotensi menjadi data yang redundan sehingga\n",
    "classifier berpotensi mempelajari data yang salah. Namun, pada kasus ini penghapusan kolom tersebut tidak terlalu\n",
    "signifikan karena nilai koefisien korelasi dari fitur tersebut tidak cukup tinggi untuk dikatakan berkorelasi.\n",
    "\"\"\"\n",
    "print(analisis)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Tugas 3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
