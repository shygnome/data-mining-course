{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used for training candidate models for air quality dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'baseline'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensuring reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_SEED = 42\n",
    "np.random.seed(CUSTOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>SO2</th>\n",
       "      <th>NO2</th>\n",
       "      <th>CO</th>\n",
       "      <th>O3</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>PRES</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>RAIN</th>\n",
       "      <th>wd</th>\n",
       "      <th>WSPM</th>\n",
       "      <th>station</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5844</td>\n",
       "      <td>2013</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>41.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>51.1197</td>\n",
       "      <td>700.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>1022.4</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NE</td>\n",
       "      <td>1.4</td>\n",
       "      <td>Wanliu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>27824</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>15.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0000</td>\n",
       "      <td>300.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>993.5</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Dingling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>25841</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>95.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>46.0000</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1012.4</td>\n",
       "      <td>-12.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ESE</td>\n",
       "      <td>1.4</td>\n",
       "      <td>Shunyi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>26986</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>34.0000</td>\n",
       "      <td>500.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>15.7</td>\n",
       "      <td>1014.6</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>WNW</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Aotizhongxin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>23848</td>\n",
       "      <td>2015</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>49.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>40.0000</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1019.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>W</td>\n",
       "      <td>0.9</td>\n",
       "      <td>Wanliu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>378693</td>\n",
       "      <td>30527</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>83.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>77.0000</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>26.9</td>\n",
       "      <td>1001.2</td>\n",
       "      <td>21.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NNE</td>\n",
       "      <td>1.1</td>\n",
       "      <td>Nongzhanguan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>378695</td>\n",
       "      <td>18071</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>41.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>56.0000</td>\n",
       "      <td>500.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1024.8</td>\n",
       "      <td>-14.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Shunyi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>378697</td>\n",
       "      <td>7768</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>105.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>77.0000</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1027.4</td>\n",
       "      <td>-13.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SSE</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Nongzhanguan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>378698</td>\n",
       "      <td>19377</td>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>123.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>33.0000</td>\n",
       "      <td>900.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>20.4</td>\n",
       "      <td>996.6</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "      <td>2.2</td>\n",
       "      <td>Dongsi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>378700</td>\n",
       "      <td>4995</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0000</td>\n",
       "      <td>200.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>W</td>\n",
       "      <td>0.9</td>\n",
       "      <td>Nongzhanguan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>312017 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           No  year  month  day  hour  PM2.5   PM10   SO2      NO2      CO  \\\n",
       "0        5844  2013     10   30    11   41.0   49.0  19.0  51.1197   700.0   \n",
       "1       27824  2016      5    3     7   15.0   26.0   2.0  11.0000   300.0   \n",
       "2       25841  2016      2   10    16   95.0   95.0  59.0  46.0000  3100.0   \n",
       "3       26986  2016      3   29     9   10.0   36.0  12.0  34.0000   500.0   \n",
       "4       23848  2015     11   19    15   49.0   49.0   2.0  40.0000  1700.0   \n",
       "...       ...   ...    ...  ...   ...    ...    ...   ...      ...     ...   \n",
       "378693  30527  2016      8   23    22   83.0  106.0   6.0  77.0000  1200.0   \n",
       "378695  18071  2015      3   23    22   41.0   87.0   6.0  56.0000   500.0   \n",
       "378697   7768  2014      1   18    15  105.0  112.0  38.0  77.0000  1600.0   \n",
       "378698  19377  2015      5   17     8  123.0  139.0  15.0  33.0000   900.0   \n",
       "378700   4995  2013      9   25     2    3.0    8.0   2.0  24.0000   200.0   \n",
       "\n",
       "          O3  TEMP    PRES  DEWP  RAIN   wd  WSPM       station  \n",
       "0        6.0  13.2  1022.4  -0.1   0.0   NE   1.4        Wanliu  \n",
       "1       72.0  15.5   993.5  -1.1   0.0   NW   3.7      Dingling  \n",
       "2       61.0   9.3  1012.4 -12.6   0.0  ESE   1.4        Shunyi  \n",
       "3       45.0  15.7  1014.6  -6.0   0.0  WNW   0.8  Aotizhongxin  \n",
       "4        2.0   4.6  1019.2   4.0   0.3    W   0.9        Wanliu  \n",
       "...      ...   ...     ...   ...   ...  ...   ...           ...  \n",
       "378693  49.0  26.9  1001.2  21.4   0.0  NNE   1.1  Nongzhanguan  \n",
       "378695  42.0  10.8  1024.8 -14.1   0.0    S   1.8        Shunyi  \n",
       "378697  43.0   4.6  1027.4 -13.8   0.0  SSE   2.3  Nongzhanguan  \n",
       "378698  68.0  20.4   996.6  15.0   0.0    S   2.2        Dongsi  \n",
       "378700  46.0   9.2  1019.0   2.5   0.0    W   0.9  Nongzhanguan  \n",
       "\n",
       "[312017 rows x 18 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '../dataset/Air quality/'\n",
    "names = [\"No\",  \"year\",  \"month\",  \"day\",  \"hour\",  \"PM2.5\",  \"PM10\",  \"SO2\",  \"NO2\",  \"CO\",  \"O3\",  \"TEMP\",  \"PRES\",  \"DEWP\",  \"RAIN\",  \"wd\",  \"WSPM\",  \"station\"]\n",
    "dataset = pd.read_csv(path + 'cleansed_air_quality.csv',  names=names)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ukuran data training (249613, 14), data testing (62404, 14)\n"
     ]
    }
   ],
   "source": [
    "# Split dataset\n",
    "feat_cols = [\"year\",  \"month\",  \"day\",  \"hour\",  \"PM10\",  \"SO2\",  \"NO2\",  \"CO\",  \"O3\",  \"TEMP\",  \"PRES\",  \"DEWP\",  \"RAIN\",  \"WSPM\"]\n",
    "excluded_cols = [\"wd\", \"station\"]\n",
    "target = \"PM2.5\"\n",
    "X, y = dataset[feat_cols], dataset[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print (\"Ukuran data training {}, data testing {}\".format(X_train.shape, X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please copy your models here as a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define base model\n",
    "def baseline_model(input_dim):\n",
    "    def _model():\n",
    "        # create model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(50, input_dim=input_dim, kernel_initializer='normal', activation='relu'))\n",
    "        model.add(Dense(1, kernel_initializer='normal'))\n",
    "        # Compile model\n",
    "        model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "        return model\n",
    "    return _model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.baseline_model.<locals>._model()>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_model(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "224651/224651 [==============================] - 47s 209us/step - loss: 619.4034\n",
      "Epoch 2/50\n",
      "224651/224651 [==============================] - 44s 197us/step - loss: 444.5106\n",
      "Epoch 3/50\n",
      "224651/224651 [==============================] - 44s 195us/step - loss: 424.4372\n",
      "Epoch 4/50\n",
      "224651/224651 [==============================] - 42s 186us/step - loss: 413.8502\n",
      "Epoch 5/50\n",
      "224651/224651 [==============================] - 49s 220us/step - loss: 406.6530\n",
      "Epoch 6/50\n",
      "224651/224651 [==============================] - 56s 251us/step - loss: 401.8578\n",
      "Epoch 7/50\n",
      "224651/224651 [==============================] - 61s 270us/step - loss: 397.9866\n",
      "Epoch 8/50\n",
      "224651/224651 [==============================] - 58s 258us/step - loss: 395.0172\n",
      "Epoch 9/50\n",
      "224651/224651 [==============================] - 64s 283us/step - loss: 393.0455\n",
      "Epoch 10/50\n",
      "224651/224651 [==============================] - 51s 226us/step - loss: 391.4979\n",
      "Epoch 11/50\n",
      "224651/224651 [==============================] - 47s 211us/step - loss: 390.1166\n",
      "Epoch 12/50\n",
      "224651/224651 [==============================] - 48s 212us/step - loss: 388.8312\n",
      "Epoch 13/50\n",
      "224651/224651 [==============================] - 41s 183us/step - loss: 387.6359\n",
      "Epoch 14/50\n",
      "224651/224651 [==============================] - 42s 185us/step - loss: 386.5513\n",
      "Epoch 15/50\n",
      "224651/224651 [==============================] - 36s 162us/step - loss: 385.5094\n",
      "Epoch 16/50\n",
      "224651/224651 [==============================] - 34s 149us/step - loss: 384.4792\n",
      "Epoch 17/50\n",
      "224651/224651 [==============================] - 34s 150us/step - loss: 382.6857\n",
      "Epoch 18/50\n",
      "224651/224651 [==============================] - 43s 192us/step - loss: 379.0653\n",
      "Epoch 22/50\n",
      "224651/224651 [==============================] - 42s 187us/step - loss: 378.6292\n",
      "Epoch 23/50\n",
      "224651/224651 [==============================] - 42s 186us/step - loss: 378.3272\n",
      "Epoch 24/50\n",
      "224651/224651 [==============================] - 43s 189us/step - loss: 377.6304\n",
      "Epoch 25/50\n",
      "224651/224651 [==============================] - 39s 176us/step - loss: 376.8659\n",
      "Epoch 26/50\n",
      "224651/224651 [==============================] - 41s 180us/step - loss: 376.4673\n",
      "Epoch 27/50\n",
      "224651/224651 [==============================] - 42s 187us/step - loss: 375.5297\n",
      "Epoch 28/50\n",
      "224651/224651 [==============================] - 42s 186us/step - loss: 375.1495\n",
      "Epoch 29/50\n",
      "224651/224651 [==============================] - 43s 190us/step - loss: 374.2608\n",
      "Epoch 30/50\n",
      "224651/224651 [==============================] - 41s 183us/step - loss: 373.5590\n",
      "Epoch 31/50\n",
      "224651/224651 [==============================] - 35s 157us/step - loss: 372.6708\n",
      "Epoch 32/50\n",
      "224651/224651 [==============================] - 35s 157us/step - loss: 370.9263\n",
      "Epoch 33/50\n",
      "224651/224651 [==============================] - 35s 156us/step - loss: 367.8010\n",
      "Epoch 34/50\n",
      "224651/224651 [==============================] - 35s 156us/step - loss: 365.2491\n",
      "Epoch 35/50\n",
      "224651/224651 [==============================] - 36s 161us/step - loss: 363.8960\n",
      "Epoch 36/50\n",
      "224651/224651 [==============================] - 38s 170us/step - loss: 362.4102\n",
      "Epoch 37/50\n",
      "224651/224651 [==============================] - 36s 162us/step - loss: 360.9276\n",
      "Epoch 38/50\n",
      "224651/224651 [==============================] - 35s 155us/step - loss: 359.8956\n",
      "Epoch 39/50\n",
      "224651/224651 [==============================] - 35s 155us/step - loss: 358.9206\n",
      "Epoch 40/50\n",
      "224651/224651 [==============================] - 35s 155us/step - loss: 358.1621\n",
      "Epoch 41/50\n",
      "224651/224651 [==============================] - 35s 155us/step - loss: 357.5034\n",
      "Epoch 42/50\n",
      "224651/224651 [==============================] - 35s 155us/step - loss: 357.0717\n",
      "Epoch 43/50\n",
      "224651/224651 [==============================] - 38s 167us/step - loss: 356.6959\n",
      "Epoch 44/50\n",
      "224651/224651 [==============================] - 36s 159us/step - loss: 356.1654\n",
      "Epoch 45/50\n",
      "224651/224651 [==============================] - 35s 155us/step - loss: 355.9475\n",
      "Epoch 46/50\n",
      "224651/224651 [==============================] - 35s 156us/step - loss: 355.5067\n",
      "Epoch 47/50\n",
      "224651/224651 [==============================] - 40s 176us/step - loss: 355.1660\n",
      "Epoch 48/50\n",
      "224651/224651 [==============================] - 39s 175us/step - loss: 354.9555\n",
      "Epoch 49/50\n",
      "224651/224651 [==============================] - 39s 175us/step - loss: 354.0857\n",
      "Epoch 50/50\n",
      "224651/224651 [==============================] - 39s 176us/step - loss: 353.0480\n",
      "24962/24962 [==============================] - 2s 74us/step\n",
      "Epoch 1/50\n",
      "224651/224651 [==============================] - 42s 188us/step - loss: 640.7124\n",
      "Epoch 2/50\n",
      "224651/224651 [==============================] - 42s 187us/step - loss: 464.0373\n",
      "Epoch 3/50\n",
      "224651/224651 [==============================] - 47s 209us/step - loss: 435.2768\n",
      "Epoch 4/50\n",
      "224651/224651 [==============================] - 42s 188us/step - loss: 424.0576\n",
      "Epoch 5/50\n",
      "224651/224651 [==============================] - 42s 188us/step - loss: 418.4470\n",
      "Epoch 6/50\n",
      "224651/224651 [==============================] - 39s 175us/step - loss: 415.1795\n",
      "Epoch 7/50\n",
      "224651/224651 [==============================] - 44s 197us/step - loss: 412.7963\n",
      "Epoch 8/50\n",
      "224651/224651 [==============================] - 43s 191us/step - loss: 411.2532\n",
      "Epoch 9/50\n",
      "224651/224651 [==============================] - 60s 266us/step - loss: 409.2442\n",
      "Epoch 10/50\n",
      "224651/224651 [==============================] - 56s 249us/step - loss: 407.1308\n",
      "Epoch 11/50\n",
      "224651/224651 [==============================] - 47s 211us/step - loss: 404.9730\n",
      "Epoch 12/50\n",
      "224651/224651 [==============================] - 43s 193us/step - loss: 402.9376\n",
      "Epoch 13/50\n",
      "224651/224651 [==============================] - 46s 206us/step - loss: 401.1367\n",
      "Epoch 14/50\n",
      "224651/224651 [==============================] - 46s 205us/step - loss: 400.2071\n",
      "Epoch 15/50\n",
      "224651/224651 [==============================] - 47s 207us/step - loss: 395.6970\n",
      "Epoch 16/50\n",
      "224651/224651 [==============================] - 50s 224us/step - loss: 393.2368\n",
      "Epoch 17/50\n",
      "224651/224651 [==============================] - 42s 187us/step - loss: 389.8181\n",
      "Epoch 18/50\n",
      "224651/224651 [==============================] - 45s 199us/step - loss: 384.5850\n",
      "Epoch 19/50\n",
      "224651/224651 [==============================] - 40s 179us/step - loss: 381.9743\n",
      "Epoch 20/50\n",
      "224651/224651 [==============================] - 41s 184us/step - loss: 380.1425\n",
      "Epoch 21/50\n",
      "224651/224651 [==============================] - 39s 172us/step - loss: 378.6575\n",
      "Epoch 22/50\n",
      "224651/224651 [==============================] - 38s 170us/step - loss: 377.1261\n",
      "Epoch 23/50\n",
      "224651/224651 [==============================] - 39s 175us/step - loss: 375.5382\n",
      "Epoch 24/50\n",
      "224651/224651 [==============================] - 42s 188us/step - loss: 371.1602\n",
      "Epoch 25/50\n",
      "224651/224651 [==============================] - 44s 195us/step - loss: 366.2868\n",
      "Epoch 26/50\n",
      "224651/224651 [==============================] - 49s 217us/step - loss: 362.8593\n",
      "Epoch 27/50\n",
      "224651/224651 [==============================] - 37s 165us/step - loss: 361.0890\n",
      "Epoch 28/50\n",
      "224651/224651 [==============================] - 36s 161us/step - loss: 360.0518\n",
      "Epoch 29/50\n",
      "224651/224651 [==============================] - 38s 169us/step - loss: 359.4158\n",
      "Epoch 30/50\n",
      "224651/224651 [==============================] - 36s 161us/step - loss: 358.8985\n",
      "Epoch 31/50\n",
      "224651/224651 [==============================] - 38s 168us/step - loss: 358.3051\n",
      "Epoch 32/50\n",
      "224651/224651 [==============================] - 41s 185us/step - loss: 357.5530\n",
      "Epoch 33/50\n",
      "224651/224651 [==============================] - 38s 170us/step - loss: 357.1546\n",
      "Epoch 34/50\n",
      "224651/224651 [==============================] - 37s 163us/step - loss: 356.0330\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224651/224651 [==============================] - 36s 160us/step - loss: 355.2055\n",
      "Epoch 36/50\n",
      "224651/224651 [==============================] - 36s 160us/step - loss: 354.4375\n",
      "Epoch 37/50\n",
      "224651/224651 [==============================] - 37s 164us/step - loss: 353.7294\n",
      "Epoch 38/50\n",
      "224651/224651 [==============================] - 36s 162us/step - loss: 353.5157\n",
      "Epoch 39/50\n",
      "224651/224651 [==============================] - 37s 164us/step - loss: 352.9404\n",
      "Epoch 40/50\n",
      "224651/224651 [==============================] - 37s 163us/step - loss: 352.5240\n",
      "Epoch 41/50\n",
      "224651/224651 [==============================] - 36s 162us/step - loss: 352.3084\n",
      "Epoch 42/50\n",
      "224651/224651 [==============================] - 36s 159us/step - loss: 351.1457\n",
      "Epoch 43/50\n",
      "224651/224651 [==============================] - 36s 162us/step - loss: 350.5084\n",
      "Epoch 44/50\n",
      "224651/224651 [==============================] - 36s 161us/step - loss: 349.8855\n",
      "Epoch 45/50\n",
      "224651/224651 [==============================] - 39s 172us/step - loss: 349.3628\n",
      "Epoch 46/50\n",
      "224651/224651 [==============================] - 36s 161us/step - loss: 349.1415\n",
      "Epoch 47/50\n",
      "224651/224651 [==============================] - 36s 162us/step - loss: 349.0322\n",
      "Epoch 48/50\n",
      "224651/224651 [==============================] - 36s 161us/step - loss: 348.3469\n",
      "Epoch 49/50\n",
      "224651/224651 [==============================] - 36s 160us/step - loss: 347.9975\n",
      "Epoch 50/50\n",
      "224651/224651 [==============================] - 36s 159us/step - loss: 348.2142\n",
      "24962/24962 [==============================] - 2s 74us/step\n",
      "Epoch 1/50\n",
      "224651/224651 [==============================] - 36s 162us/step - loss: 621.2969\n",
      "Epoch 2/50\n",
      "224651/224651 [==============================] - 36s 161us/step - loss: 451.1783\n",
      "Epoch 3/50\n",
      "224651/224651 [==============================] - 37s 165us/step - loss: 427.0786\n",
      "Epoch 4/50\n",
      "224651/224651 [==============================] - 36s 161us/step - loss: 417.0791\n",
      "Epoch 5/50\n",
      "224651/224651 [==============================] - 36s 161us/step - loss: 411.4350\n",
      "Epoch 6/50\n",
      "224651/224651 [==============================] - 37s 164us/step - loss: 407.7995\n",
      "Epoch 7/50\n",
      "224651/224651 [==============================] - 37s 163us/step - loss: 405.5203\n",
      "Epoch 8/50\n",
      "224651/224651 [==============================] - 36s 161us/step - loss: 404.0598\n",
      "Epoch 9/50\n",
      "224651/224651 [==============================] - 36s 161us/step - loss: 402.6410\n",
      "Epoch 10/50\n",
      "224651/224651 [==============================] - 37s 164us/step - loss: 401.6369\n",
      "Epoch 11/50\n",
      "224651/224651 [==============================] - 37s 166us/step - loss: 400.4694\n",
      "Epoch 12/50\n",
      "224651/224651 [==============================] - 37s 163us/step - loss: 398.4848\n",
      "Epoch 13/50\n",
      "224651/224651 [==============================] - 36s 161us/step - loss: 395.8148\n",
      "Epoch 14/50\n",
      "224651/224651 [==============================] - 37s 163us/step - loss: 391.0422\n",
      "Epoch 15/50\n",
      "224651/224651 [==============================] - 37s 164us/step - loss: 388.3686\n",
      "Epoch 16/50\n",
      "224651/224651 [==============================] - 36s 162us/step - loss: 386.1289\n",
      "Epoch 17/50\n",
      "224651/224651 [==============================] - 36s 161us/step - loss: 384.4699\n",
      "Epoch 18/50\n",
      "224651/224651 [==============================] - 36s 161us/step - loss: 383.2775\n",
      "Epoch 19/50\n",
      "224651/224651 [==============================] - 41s 182us/step - loss: 382.0037\n",
      "Epoch 20/50\n",
      "224651/224651 [==============================] - 37s 165us/step - loss: 381.3383\n",
      "Epoch 21/50\n",
      "224651/224651 [==============================] - 36s 162us/step - loss: 380.4618\n",
      "Epoch 22/50\n",
      "224651/224651 [==============================] - 37s 164us/step - loss: 378.1118\n",
      "Epoch 23/50\n",
      "224651/224651 [==============================] - 37s 163us/step - loss: 375.9208\n",
      "Epoch 24/50\n",
      "224651/224651 [==============================] - 37s 165us/step - loss: 374.6368\n",
      "Epoch 25/50\n",
      "224651/224651 [==============================] - 36s 162us/step - loss: 373.2900\n",
      "Epoch 26/50\n",
      "224651/224651 [==============================] - 36s 162us/step - loss: 372.6131\n",
      "Epoch 27/50\n",
      "224651/224651 [==============================] - 37s 166us/step - loss: 371.1528\n",
      "Epoch 28/50\n",
      "224651/224651 [==============================] - 36s 162us/step - loss: 370.1555\n",
      "Epoch 29/50\n",
      "224651/224651 [==============================] - 37s 163us/step - loss: 369.6209\n",
      "Epoch 30/50\n",
      "224651/224651 [==============================] - 36s 162us/step - loss: 368.6101\n",
      "Epoch 31/50\n",
      "224651/224651 [==============================] - 36s 162us/step - loss: 367.9258\n",
      "Epoch 32/50\n",
      "224651/224651 [==============================] - 36s 162us/step - loss: 367.0068\n",
      "Epoch 33/50\n",
      "224651/224651 [==============================] - 36s 162us/step - loss: 365.4897\n",
      "Epoch 34/50\n",
      "224651/224651 [==============================] - 39s 174us/step - loss: 364.0859\n",
      "Epoch 35/50\n",
      "224651/224651 [==============================] - 36s 162us/step - loss: 363.2363\n",
      "Epoch 36/50\n",
      "224651/224651 [==============================] - 36s 162us/step - loss: 362.5151\n",
      "Epoch 37/50\n",
      "224651/224651 [==============================] - 39s 173us/step - loss: 361.6197\n",
      "Epoch 38/50\n",
      "224651/224651 [==============================] - 38s 169us/step - loss: 360.8941\n",
      "Epoch 39/50\n",
      "224651/224651 [==============================] - 38s 168us/step - loss: 360.2227\n",
      "Epoch 40/50\n",
      "224651/224651 [==============================] - 38s 168us/step - loss: 359.2451\n",
      "Epoch 41/50\n",
      "224651/224651 [==============================] - 37s 166us/step - loss: 358.5788\n",
      "Epoch 42/50\n",
      "224651/224651 [==============================] - 37s 166us/step - loss: 357.7896\n",
      "Epoch 43/50\n",
      "224651/224651 [==============================] - 38s 168us/step - loss: 357.2616\n",
      "Epoch 44/50\n",
      "224651/224651 [==============================] - 38s 170us/step - loss: 356.5895\n",
      "Epoch 45/50\n",
      "224651/224651 [==============================] - 37s 166us/step - loss: 356.0936\n",
      "Epoch 46/50\n",
      "224651/224651 [==============================] - 38s 168us/step - loss: 355.8985\n",
      "Epoch 47/50\n",
      "224651/224651 [==============================] - 37s 167us/step - loss: 355.2877\n",
      "Epoch 48/50\n",
      "224651/224651 [==============================] - 38s 171us/step - loss: 355.0563\n",
      "Epoch 49/50\n",
      "224651/224651 [==============================] - 37s 164us/step - loss: 354.8728\n",
      "Epoch 50/50\n",
      "224651/224651 [==============================] - 36s 161us/step - loss: 354.4936\n",
      "24962/24962 [==============================] - 2s 75us/step\n",
      "Epoch 1/50\n",
      "224652/224652 [==============================] - 38s 169us/step - loss: 657.1032\n",
      "Epoch 2/50\n",
      "224652/224652 [==============================] - 38s 167us/step - loss: 511.3755\n",
      "Epoch 3/50\n",
      "224652/224652 [==============================] - 40s 179us/step - loss: 493.3934\n",
      "Epoch 4/50\n",
      "224652/224652 [==============================] - 38s 168us/step - loss: 484.5127\n",
      "Epoch 5/50\n",
      "224652/224652 [==============================] - ETA: 0s - loss: 479.373 - 38s 167us/step - loss: 479.4403\n",
      "Epoch 6/50\n",
      "224652/224652 [==============================] - 38s 168us/step - loss: 476.2692\n",
      "Epoch 7/50\n",
      "224652/224652 [==============================] - 38s 167us/step - loss: 473.1444\n",
      "Epoch 8/50\n",
      "224652/224652 [==============================] - 37s 166us/step - loss: 471.1908\n",
      "Epoch 9/50\n",
      "224652/224652 [==============================] - 38s 167us/step - loss: 468.7037\n",
      "Epoch 10/50\n",
      "224652/224652 [==============================] - 37s 165us/step - loss: 466.2875\n",
      "Epoch 11/50\n",
      "224652/224652 [==============================] - 37s 165us/step - loss: 463.7679\n",
      "Epoch 12/50\n",
      "224652/224652 [==============================] - 37s 165us/step - loss: 461.5096\n",
      "Epoch 13/50\n",
      "224652/224652 [==============================] - 38s 168us/step - loss: 460.2073\n",
      "Epoch 14/50\n",
      "224652/224652 [==============================] - 37s 164us/step - loss: 458.4877\n",
      "Epoch 15/50\n",
      "224652/224652 [==============================] - 37s 165us/step - loss: 444.9476\n",
      "Epoch 16/50\n",
      "224652/224652 [==============================] - 37s 165us/step - loss: 414.0301\n",
      "Epoch 17/50\n",
      "224652/224652 [==============================] - 37s 165us/step - loss: 398.2989\n",
      "Epoch 18/50\n",
      "224652/224652 [==============================] - 38s 168us/step - loss: 392.7241\n",
      "Epoch 19/50\n",
      "224652/224652 [==============================] - 40s 177us/step - loss: 390.9939\n",
      "Epoch 20/50\n",
      "224652/224652 [==============================] - 38s 169us/step - loss: 390.0060\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224652/224652 [==============================] - 37s 165us/step - loss: 389.4906\n",
      "Epoch 22/50\n",
      "224652/224652 [==============================] - 38s 168us/step - loss: 389.0802\n",
      "Epoch 23/50\n",
      "224652/224652 [==============================] - 37s 167us/step - loss: 388.3090\n",
      "Epoch 24/50\n",
      "224652/224652 [==============================] - 37s 165us/step - loss: 388.1606\n",
      "Epoch 25/50\n",
      "224652/224652 [==============================] - 38s 168us/step - loss: 388.1120\n",
      "Epoch 26/50\n",
      "224652/224652 [==============================] - 38s 167us/step - loss: 387.6382\n",
      "Epoch 27/50\n",
      "224652/224652 [==============================] - 40s 178us/step - loss: 385.6663\n",
      "Epoch 28/50\n",
      "224652/224652 [==============================] - 37s 165us/step - loss: 383.3703\n",
      "Epoch 29/50\n",
      "224652/224652 [==============================] - 37s 165us/step - loss: 381.4384\n",
      "Epoch 30/50\n",
      "224652/224652 [==============================] - 38s 167us/step - loss: 379.0826\n",
      "Epoch 31/50\n",
      "224652/224652 [==============================] - 37s 166us/step - loss: 376.7925\n",
      "Epoch 32/50\n",
      "224652/224652 [==============================] - 37s 165us/step - loss: 374.9438\n",
      "Epoch 33/50\n",
      " 74790/224652 [========>.....................] - ETA: 24s - loss: 375.5226"
     ]
    }
   ],
   "source": [
    "# evaluate model with standardized dataset\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=baseline_model(X_train.shape[1]), epochs=50, batch_size=5, verbose=1)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10)\n",
    "results = cross_val_score(pipeline, X_train, y_train, cv=kfold)\n",
    "print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
